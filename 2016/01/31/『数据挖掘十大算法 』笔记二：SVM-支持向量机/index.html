<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>『数据挖掘十大算法 』笔记二：SVM-支持向量机 | AaronChou page</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="『数据挖掘十大算法 』笔记二：SVM-支持向量机">
<meta property="og:type" content="article">
<meta property="og:title" content="『数据挖掘十大算法 』笔记二：SVM-支持向量机">
<meta property="og:url" content="https://insanelife.github.io/2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/index.html">
<meta property="og:site_name" content="AaronChou page">
<meta property="og:description" content="『数据挖掘十大算法 』笔记二：SVM-支持向量机">
<meta property="og:image" content="http://img.blog.csdn.net/20170316203804430?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2hpbmUxOTkzMDgyMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:updated_time" content="2017-03-21T02:16:44.485Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="『数据挖掘十大算法 』笔记二：SVM-支持向量机">
<meta name="twitter:description" content="『数据挖掘十大算法 』笔记二：SVM-支持向量机">
<meta name="twitter:image" content="http://img.blog.csdn.net/20170316203804430?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2hpbmUxOTkzMDgyMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
  
    <link rel="alternative" href="/atom.xml" title="AaronChou page" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  
      <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          rootUrl: '/',
          fancybox: true,
          animate: true,
          isHome: false,
          isPost: true,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            
            <img lazy-src="/img/head.jpg" class="js-avatar">
            
        </a>

        <hgroup>
          <h1 class="header-author"><a href="/" title="Hi Mate">AaronChou</a></h1>
        </hgroup>

        
        <p class="header-subtitle">立刻有</p>
        
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="https://insanelife.github.io/">博客首页</a></li>
                        
                            <li><a href="https://github.com/InsaneLife">作品展示</a></li>
                        
                            <li><a href="/about">留言打卡</a></li>
                        
                            <li><a href="http://blog.csdn.net/shine19930820">CSDN</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl mail" target="_blank" href="/zhiyangzhou@foxmail.com" title="mail">mail</a>
                            
                                <a class="fl github" target="_blank" href="https://github.com/InsaneLife" title="github">github</a>
                            
                                <a class="fl zhihu" target="_blank" href="#" title="zhihu">zhihu</a>
                            
                                <a class="fl weibo" target="_blank" href="http://weibo.com/zhiyangchou/profile" title="weibo">weibo</a>
                            
                                <a class="fl google" target="_blank" href="#" title="google">google</a>
                            
                                <a class="fl twitter" target="_blank" href="#" title="twitter">twitter</a>
                            
                                <a class="fl linkedin" target="_blank" href="#" title="linkedin">linkedin</a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/O2O/" style="font-size: 10px;">O2O</a> <a href="/tags/不平衡学习/" style="font-size: 10px;">不平衡学习</a> <a href="/tags/决策树/" style="font-size: 10px;">决策树</a> <a href="/tags/天池/" style="font-size: 10px;">天池</a> <a href="/tags/支持向量机/" style="font-size: 10px;">支持向量机</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/算法/" style="font-size: 20px;">算法</a>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="https://insanelife.github.io/">name</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">爱运动、爱交友、爱旅行、喜欢接触新鲜事物、迎接新的挑战，更爱游离于错综复杂的编码与逻辑中</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="Me">AaronChou</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/head.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="Me">AaronChou</a></h1>
            </hgroup>
            
            <p class="header-subtitle">立刻有</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="https://insanelife.github.io/">博客首页</a></li>
                
                    <li><a href="https://github.com/InsaneLife">作品展示</a></li>
                
                    <li><a href="/about">留言打卡</a></li>
                
                    <li><a href="http://blog.csdn.net/shine19930820">CSDN</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="mail" target="_blank" href="/zhiyangzhou@foxmail.com" title="mail">mail</a>
                    
                        <a class="github" target="_blank" href="https://github.com/InsaneLife" title="github">github</a>
                    
                        <a class="zhihu" target="_blank" href="#" title="zhihu">zhihu</a>
                    
                        <a class="weibo" target="_blank" href="http://weibo.com/zhiyangchou/profile" title="weibo">weibo</a>
                    
                        <a class="google" target="_blank" href="#" title="google">google</a>
                    
                        <a class="twitter" target="_blank" href="#" title="twitter">twitter</a>
                    
                        <a class="linkedin" target="_blank" href="#" title="linkedin">linkedin</a>
                    
                </div>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap"><article id="post-『数据挖掘十大算法 』笔记二：SVM-支持向量机" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/" class="article-date">
      <time datetime="2016-01-31T07:30:16.000Z" itemprop="datePublished">2016-01-31</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      『数据挖掘十大算法 』笔记二：SVM-支持向量机
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/支持向量机/">支持向量机</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>[TOC]</p>
<h1 id="数据挖掘Top-10算法"><a href="#数据挖掘Top-10算法" class="headerlink" title="数据挖掘Top 10算法"></a>数据挖掘Top 10算法</h1><p><strong>C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART</strong></p>
<hr>
<h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><p>支持向量机，英文为Support Vector Machine，是一种分类模型，属于<strong>监督式学习</strong>的方法，它的基本模型是定义在<strong>特征空间</strong>上的<strong>间隔最大</strong>的<strong>线性分类器</strong>，这一点是和感知机不同的地方（感知机基于误分类的损失函数，利用梯度下降法获得损失函数极小化的超平面）。</p>
<p>支持向量机利用<strong>核函数</strong>将输入从输入空间<strong>映射</strong>到特征空间，在<strong>特征空间</strong>里建立有一个<strong>最大间隔超平面</strong>。</p>
<p>支持向量机将向量映射到一个更高维的空间里，在这个空间里建立有一个最大间隔超平面。<br><strong>核函数</strong>表示将输入从输入空间映射到特征空间得到特征向量之间<strong>内积</strong>。通过核函数可以学习非线性支持向量机，等价于隐式地在<strong>高维的特征空间</strong>学习线性支持向量机。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">st=&gt;start: Start</div><div class="line">e=&gt;end: End</div><div class="line">in=&gt;inputoutput: 输入空间</div><div class="line">cond1=&gt;condition: 是否线性可分</div><div class="line">op1=&gt;operation: 核函数(kernel function)</div><div class="line">io=&gt;inputoutput: 特征空间</div><div class="line">op2=&gt;operation: 寻找间隔最大化超平面</div><div class="line">out=&gt;inputoutput: 分类模型</div><div class="line">in-&gt;cond1</div><div class="line">cond1(no)-&gt;op1-&gt;io</div><div class="line">cond1(yes)-&gt;io</div><div class="line">io-&gt;op2-&gt;out</div></pre></td></tr></table></figure>
<h1 id="线性可分支持向量机"><a href="#线性可分支持向量机" class="headerlink" title="线性可分支持向量机"></a>线性可分支持向量机</h1><p>既然线性可分，学习的目标为在特征空间中找到一个分离超平面，能够将实例分到不同的类。</p>
<p>给定线性可分训练数据集，通过间隔最大化求解相应的凸二次规划问题学习得到分离超平面为</p>
<script type="math/tex; mode=display">\omega^*+b=0</script><p>相应的分类决策函数为</p>
<script type="math/tex; mode=display">f(x) = sign(\omega^*+b)</script><p>即为线性可分支持向量机。</p>
<p>间隔最大化相应的间隔分为函数间隔和几何间隔。</p>
<h2 id="函数间隔和几何间隔"><a href="#函数间隔和几何间隔" class="headerlink" title="函数间隔和几何间隔"></a>函数间隔和几何间隔</h2><p><strong>函数间隔</strong>：对于给定的训练数据集T和超平面(w,b)，定义超平面(w,b)关于样本点$(x_i,y_i)$的函数间隔为</p>
<script type="math/tex; mode=display">\hat{\varUpsilon}_i = y_i(w*x_i+b)</script><p>当超平面并未改变，只是成比例改变w和b的时候，函数间隔也会发生变化，如变成2w和2b，超平面未变函数间隔却变成了2倍，所以需要对法向量w加一些约束，如规范化，||w||=1,是的间隔确定，变成了几何间隔。</p>
<p><strong>函数间隔</strong>：对于给定的训练数据集T和超平面(w,b)，定义超平面(w,b)关于样本点$(x_i,y_i)$的几何间隔为</p>
<script type="math/tex; mode=display">\hat{\varUpsilon}_i = y_i(\frac{w}{||w||}*x_i+\frac{b}{||w||})</script><p>定义超平面(w,b)关于训练数据集T的函数间隔为超平面(w,b)关于T中所有样本点$(x_i,y_i)$的几何间隔最小值，即</p>
<script type="math/tex; mode=display">\varUpsilon = \min\limits_{i=1,···,N} \hat{\varUpsilon}_i</script><p>超平面(w,b)关于样本点$(x_i,y_i)$的几何间隔一般是实例点到超平面的带符号距离，<strong>样本点被超平面正确分类时就是实例点到超平面的距离。</strong></p>
<h2 id="间隔最大化"><a href="#间隔最大化" class="headerlink" title="间隔最大化"></a>间隔最大化</h2><p>将问题表示为下面约束最优化问题：</p>
<script type="math/tex; mode=display">\max\limits_{w,b} \varUpsilon</script><script type="math/tex; mode=display">s.t. \ \  y_i(\frac{w}{||w||}*x_i+\frac{b}{||w||}) \geq \varUpsilon,\ \ i=1,2,···,N​</script><p>约束条件表示超平面(w,b)关于每个样本点$(x_i,y_i)$的几何间隔至少是$\varUpsilon$</p>
<p>等价于下面约束最优化问题：</p>
<script type="math/tex; mode=display">\max\limits_{w,b} \frac{\varUpsilon}{||w||}</script><script type="math/tex; mode=display">s.t. \ \  y_i(w*x_i + b) \geq \varUpsilon,\ \ i=1,2,···,N</script><p>函数间隔取值并不影响最优化问题的解，所以取$\hat{\varUpsilon=1}$，将其带入最优化问题，而最大化$\frac{1}{||w||}$和最小化$\frac{1}{2} ||w||^2$等价，于是转化为一个凸二次规划问题：</p>
<script type="math/tex; mode=display">\min\limits_{w,b} \frac{1}{2} {||w||^2}</script><script type="math/tex; mode=display">s.t. \ \  y_i(w*x_i + b) - 1 \geq 0,\ \ i=1,2,···,N</script><h3 id="间隔最大化算法"><a href="#间隔最大化算法" class="headerlink" title="间隔最大化算法"></a><strong>间隔最大化算法</strong></h3><p>输入：线性可分数据集$T={(x_1,y_1),(x_2,y_2),···,(x_N,y_N)}$，其中，$x_i \in \chi = R^n, y_i \in \gamma={-1,+1}, \  i=1,2,···,N $；</p>
<p>输出：最大间隔超平面和分类决策函数；</p>
<ol>
<li><p>构造并求解约束最优化问题：</p>
<script type="math/tex; mode=display">\min\limits_{w,b} \frac{1}{2} {||w||^2} \\ s.t. \ \  y_i(w*x_i + b) - 1 \geq 0,\ \ i=1,2,···,N</script><p>求得最优解$w^<em>, b^</em>$</p>
</li>
<li><p>由此得到超平面：</p>
<script type="math/tex; mode=display">w^* *x + b^* = 0</script><p>分类决策函数：</p>
<script type="math/tex; mode=display">f(x) = sign(\omega^*+b)</script></li>
</ol>
<h3 id="支持向量和间隔边界"><a href="#支持向量和间隔边界" class="headerlink" title="支持向量和间隔边界"></a>支持向量和间隔边界</h3><p>线性可分的情况下，训练数据集的样本点与分离超平面距离最近的样本点的实例称为支持向量（support vector），支持向量是使得约束条件等号成立的点，即</p>
<script type="math/tex; mode=display">y_i(w*x + b) = 0</script><p>如图，$H_1, H_2$就是支持向量。</p>
<p><center><img src="http://img.blog.csdn.net/20170316203804430?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2hpbmUxOTkzMDgyMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></center></p>
<p><strong>支持向量</strong>在确定分离超平面中起着<strong>决定性作用</strong>，所以这种分类模型称为<strong>支持向量机</strong>。</p>
<h2 id="学习的对偶算法"><a href="#学习的对偶算法" class="headerlink" title="学习的对偶算法"></a>学习的对偶算法</h2><p>应用拉格朗日对偶性，通过求解对偶问题得到原始问题的最优解，就是线性可分支持向量机的对偶算法，有点在于：</p>
<ol>
<li>对偶问题更容易求解。</li>
<li>方便引入核函数，进而推广到非线性问题求解。</li>
</ol>
<p>定义拉格朗日函数：</p>
<script type="math/tex; mode=display">L(w,b,\alpha) = \frac{1}{2} ||w||^2 - \sum\limits_{i=1}^N \alpha_i y_i(w*x_i + b ) + \sum\limits_{i=1}^N \alpha_i  \qquad 1.18</script><p>原始问题的对偶问题是极大极小问题：</p>
<script type="math/tex; mode=display">\max\limits_\alpha \min\limits_{w,b} L(w,b,\alpha)</script><ul>
<li><p>首先求$\min\limits_{w,b} L(w,b,\alpha)$:</p>
<p>将拉格朗日函数对$w,b$求偏导数并令其等于零，获得极值点。</p>
<script type="math/tex; mode=display">\nabla_w L(w,b,\alpha) = w - \sum\limits_{i=1}^N \alpha_i y_i x_i = 0 \qquad 1.19</script><script type="math/tex; mode=display">\nabla_b l(w,b,\alpha) = \sum\limits_{i=1}^N \alpha_i y_i = 0 \qquad 1.20</script><p>然后回带到1.18式，得到：</p>
<script type="math/tex; mode=display">\min\limits_{w,b} L(w,b,\alpha) = -\frac{1}{2} \sum\limits_{i=1}^N \sum\limits_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i*x_j) + \sum\limits_{i=1}^N \alpha_i</script></li>
<li><p>求$\min\limits_{w,b} L(w,b,\alpha)$对$\alpha$的极大:</p>
<script type="math/tex; mode=display">\max\limits_\alpha ( -\frac{1}{2} \sum\limits_{i=1}^N \sum\limits_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i*x_j) + \sum\limits_{i=1}^N \alpha_i)</script><script type="math/tex; mode=display">s.t. \ \ \sum\limits_{i=1}^N \alpha_i y_i = 0 \\ \alpha \geq 0, \  i=1,2,...,N</script></li>
</ul>
<h3 id="线性可分支持向量机学习算法"><a href="#线性可分支持向量机学习算法" class="headerlink" title="线性可分支持向量机学习算法"></a><strong>线性可分支持向量机学习算法</strong></h3><p>输入：线性可分数据集T={(x_1,y_1),(x_2,y_2),···,(x_N,y_N)}，其中，x_i \in \chi = R^n, y_i \in \gamma={-1,+1}, \  i=1,2,···,N ；</p>
<p>输出：最大间隔超平面和分类决策函数；</p>
<ol>
<li><p>构造并求解约束最优化问题：</p>
<script type="math/tex; mode=display">\min\limits_\alpha ( \frac{1}{2} \sum\limits_{i=1}^N \sum\limits_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i*x_j) - \sum\limits_{i=1}^N \alpha_i)</script><script type="math/tex; mode=display">s.t. \ \ \sum\limits_{i=1}^N \alpha_i y_i = 0 \\ \alpha \geq 0, \  i=1,2,...,N</script><p>求得最优解$\alpha^<em> = (\alpha_1^</em>,\alpha_2^<em>,…\alpha_N^</em>)^T$</p>
</li>
<li><p>计算：</p>
<script type="math/tex; mode=display">w^* = \sum\limits_{i=1}^N \alpha_i^* y_i x_i</script><p>并选择$\alpha_i^<em>$ 的一个正分量$\alpha_j^</em> \geq 0$（其实这个点就是一个支持向量），计算：</p>
<script type="math/tex; mode=display">b = y_i - \sum\limits_{i=1}^N \alpha_i^* y_i (x_i * x_j)</script></li>
<li><p>由此得到超平面：</p>
<script type="math/tex; mode=display">w^* *x + b^* = 0</script><p>分类决策函数：</p>
<script type="math/tex; mode=display">f(x) = sign(\omega^*+b)</script></li>
</ol>
<h1 id="线性支持向量机和软间隔最大化"><a href="#线性支持向量机和软间隔最大化" class="headerlink" title="线性支持向量机和软间隔最大化"></a>线性支持向量机和软间隔最大化</h1><p>线性支持向量机<strong>区别</strong>于线性可分支持向量机，在于面对的是线性不可分的数据，修改硬间隔最大化，变为软间隔最大化。其实一般实际数据都是线性不可分的，因为总会有随机噪声存在。</p>
<p>线性不可分意味着样本点不能满足函数间隔大于1的约束条件，因此在每个样本点引进一个松弛变量$\xi_i \geq 0$，使得约束条件为：</p>
<script type="math/tex; mode=display">y_i(w*x_i +b) \geq 1-\xi_i</script><p>因此目标函数也发生变化，线性不可分支持向量机学习问题变成如下凸二次优化问题：</p>
<script type="math/tex; mode=display">\min\limits_{w,b，\xi} \frac{1}{2} {||w||^2}+ C \sum\limits_{i=1}^N \xi_i \\ s.t. \ \  y_i(w*x_i + b) \geq 1- \xi_i,i=1,2,···,N\\ \xi_i \geq 0 i=1,2,···,N</script><p>其中C是调和间隔最大化和误分类点的个数两者的系数，C比较大时对误分类的惩罚增大。</p>
<h2 id="线性支持向量机学习算法"><a href="#线性支持向量机学习算法" class="headerlink" title="线性支持向量机学习算法"></a><strong>线性支持向量机学习算法</strong></h2><p>输入：线性可分数据集$T={(x_1,y_1),(x_2,y_2),···,(x_N,y_N)}$，其中，$x_i \in \chi = R^n, y_i \in \gamma={-1,+1}, \  i=1,2,···,N$ ；</p>
<p>输出：最大间隔超平面和分类决策函数；</p>
<ol>
<li><p>选择惩罚项参数$C \geq 0$，构造并求解凸二次规划问题：</p>
<script type="math/tex; mode=display">\min\limits_\alpha ( \frac{1}{2} \sum\limits_{i=1}^N \sum\limits_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i*x_j) - \sum\limits_{i=1}^N \alpha_i)</script><script type="math/tex; mode=display">s.t. \ \ \sum\limits_{i=1}^N \alpha_i y_i = 0 \\  0\leq \alpha \leq C, \  i=1,2,...,N</script><p>求得最优解$\alpha^<em> = (\alpha_1^</em>,\alpha_2^<em>,…\alpha_N^</em>)^T$</p>
</li>
<li><p>计算：</p>
<script type="math/tex; mode=display">w^* = \sum\limits_{i=1}^N \alpha_i^* y_i x_i</script><p>并选择$\alpha_i^<em>$ 的一个正分量$C \geq \alpha_j^</em> \geq 0$（其实这个点就是一个支持向量），计算：</p>
<script type="math/tex; mode=display">b = y_i - \sum\limits_{i=1}^N \alpha_i^* y_i (x_i * x_j)</script></li>
<li><p>由此得到超平面：</p>
<script type="math/tex; mode=display">w^* *x + b^* = 0</script><p>分类决策函数：</p>
<script type="math/tex; mode=display">f(x) = sign(\omega^*+b)</script></li>
</ol>
<p>步骤2中，由于原始问题对b的解并不唯一，所以实际计算时选取在<strong>所有符合条件的样本点上的平均值。</strong></p>
<h1 id="非线性支持向量机和核函数"><a href="#非线性支持向量机和核函数" class="headerlink" title="非线性支持向量机和核函数"></a>非线性支持向量机和核函数</h1><h2 id="核技巧"><a href="#核技巧" class="headerlink" title="核技巧"></a>核技巧</h2><h3 id="非线性分类问题"><a href="#非线性分类问题" class="headerlink" title="非线性分类问题"></a><strong>非线性分类问题</strong></h3><p>对于给定的训练数据集$T={(x_1,y_1),(x_2,y_2),···,(x_N,y_N)}$，其中，$x_i \in \chi = R^n, y_i \in \gamma={-1,+1}, \  i=1,2,···,N$ 。如果能用$R^n$中单的一个超曲面将正负样例正确分开，则称这个问题为非线性可分问题。</p>
<p>非线性问题难以求解，所以<strong>进行一个非线性变换，将非线性问题变换为线性问题，通过解变换后的线性问题的方法求解原来的非线性问题。</strong></p>
<p>核技巧的基本思想就是通过一个非线性变换将输入空间对应一个特征空间，使得在输入空间中的超曲面模型对应特征空间中的超平面模型，这样分类问题的学习就可以通过在特征空间中求解线性支持向量机完成。</p>
<h3 id="核函数定义"><a href="#核函数定义" class="headerlink" title="核函数定义"></a><strong>核函数定义</strong></h3><p><strong>核函数</strong>： 设$\chi$是输入空间（欧式空间），设$H$为特征空间（希尔伯特空间），如果存在一个从$\chi $到$H$的映射:</p>
<script type="math/tex; mode=display">\phi(x):\chi \rightarrow H</script><p>使得对所有的$x,z \in \chi$，函数$K(x,z)$满足条件：</p>
<script type="math/tex; mode=display">K(x,z) = \phi(x)*\phi(z)</script><p>则称$K(x,z)$为核函数，$\phi(x)$为映射函数，式中$\phi(x)*\phi(x)$为内积。</p>
<p>核技巧的思想在于学习预测中只定义核函数$K(x,z)$，而显式地定义函数映射。因为通常直接计算核函数$K(x,z)$比较容易，而通过$\phi(x),\phi(z)$计算$K(x,z)$并不容易。</p>
<h3 id="核技巧在支持向量机中的应用"><a href="#核技巧在支持向量机中的应用" class="headerlink" title="核技巧在支持向量机中的应用"></a><strong>核技巧在支持向量机中的应用</strong></h3><p>在支持向量机对偶问题中，目标函数和决策函数都涉及输入实例之间的内积形式，在对偶问题中目标函数$x_i<em>x_j$可以用核函数$K(x_i,x_j) = \phi(x_i)</em>\phi(x_j)$代替。目标函数变为：</p>
<script type="math/tex; mode=display">\min\limits_\alpha ( \frac{1}{2} \sum\limits_{i=1}^N \sum\limits_{j=1}^N \alpha_i \alpha_j y_i y_j K(x_i,x_j) - \sum\limits_{i=1}^N \alpha_i)</script><p>分类决策函数变为：</p>
<script type="math/tex; mode=display">f(x) = sign(\sum\limits_{i=1}^{N_s} \alpha_i^* y_i \phi(x_i) *\phi(x) + b^*)\\= sign(\sum\limits_{i=1}^{N_s} \alpha_i^* y_i K(x_i,x) + b^*)</script><h2 id="正定核"><a href="#正定核" class="headerlink" title="正定核"></a>正定核</h2><p>不用构造$\phi(x)$能否直接判断给定函数$K(x,z)$是否是核函数？或者说满足核函数需要什么条件呢？</p>
<p>首先为什么要是正定核：<strong>当$K(x,z)$是正定核函数时，这是一个凸二次规划问题，解释存在的。</strong></p>
<p><strong>正定核函数（正定核）</strong>的<strong>充要条件</strong>：设$K:\chi \times \chi \rightarrow R$是对称函数，则$K(x,z)$为正定核函数的充要条件是对任意$x_i \in \chi , i=1,2,…,m,  \ K(x,z)$对应的Gram矩阵：</p>
<script type="math/tex; mode=display">K = [K(x_i,x_j)]_{m \times m}</script><p>是半正定矩阵。</p>
<h2 id="常用核函数"><a href="#常用核函数" class="headerlink" title="常用核函数"></a><strong>常用核函数</strong></h2><ol>
<li><p>多项式核函数。</p>
<p>$K(x,z) = (x*z +1)^p$</p>
<p>对应的支持向量机是一个p次多项式分类器，再次情况下，分类决策函数为：</p>
<script type="math/tex; mode=display">f(x) = sign(\sum\limits_{i=1}^{N_s} \alpha_i^* y_i (x_i*x +1)^p + b^*)</script></li>
<li><p>高斯核函数。</p>
<script type="math/tex; mode=display">K(x,z) = \exp(-\frac{||x-z||^2}{2\sigma^2})</script><p>对应的支持向量机是高斯径向基函数分类器，分类决策函数为：</p>
<script type="math/tex; mode=display">f(x) = sign(\sum\limits_{i=1}^{N_s} \alpha_i^* y_i \exp(-\frac{||x-z||^2}{2\sigma^2}) + b^*)</script></li>
<li><p>字符串核函数。</p>
<p>核函数不仅可以定义在欧式空间，还可以定义在离散数据集合熵，比如字符串核是定义在字符串集合上的核函数。字符串核函数在文本分类、信息检索、生物信息学方面都有应用。</p>
</li>
</ol>
<h2 id="非线性支持向量机学习算法"><a href="#非线性支持向量机学习算法" class="headerlink" title="非线性支持向量机学习算法"></a><strong>非线性支持向量机学习算法</strong></h2><p>输入：训练数据集$T={(x_1,y_1),(x_2,y_2),···,(x_N,y_N)}$，其中，$x_i \in \chi = R^n, y_i \in \gamma={-1,+1}, \  i=1,2,···,N $；</p>
<p>输出：分类决策函数；</p>
<ol>
<li><p>选取适当的核函数$K(x,z)$和适当的参数C，构造并求解最优化问题：</p>
<script type="math/tex; mode=display">\min\limits_\alpha ( \frac{1}{2} \sum\limits_{i=1}^N \sum\limits_{j=1}^N \alpha_i \alpha_j y_i y_j K(x_i,x_j) - \sum\limits_{i=1}^N \alpha_i)</script><script type="math/tex; mode=display">s.t. \ \ \sum\limits_{i=1}^N \alpha_i y_i = 0 \\ C \geq\alpha \geq 0, \  i=1,2,...,N</script><p>求得最优解$\alpha^<em> = (\alpha_1^</em>,\alpha_2^<em>,…\alpha_N^</em>)^T$</p>
</li>
<li><p>选择$\alpha_i^<em>$ 的一个正分量$\alpha_j^</em> \geq 0$（其实这个点就是一个支持向量），计算：</p>
<script type="math/tex; mode=display">b = y_i - \sum\limits_{i=1}^N \alpha_i^* y_i K(x_i , x_j)</script></li>
<li><p>构造分类决策函数：</p>
<script type="math/tex; mode=display">f(x) = sign(\sum\limits_{i=1}^{N_s} \alpha_i^* y_i K(x_i,x) + b^*)</script></li>
</ol>
<p>当$K(x,z)$是正定核函数时，这是一个凸二次规划问题，解释存在的。</p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="算法分类"><a href="#算法分类" class="headerlink" title="算法分类"></a>算法分类</h2><p>​    机器学习算法按照<strong>学习方式</strong>分为<strong>监督学习、非监督学习、半监督学习、强化学习</strong></p>
<p><strong>监督学习</strong>：从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。训练集中的目标是由人标注的。</p>
<p><strong>非监督式学习</strong>：与监督学习相比，训练集没有人为标注的结果。常见的非监督式学习算法有聚类。</p>
<p><strong>半监督式学习</strong>：输入数据部分被标识，部分没有被标识，介于监督式学习与非监督式学习之间。常见的半监督式学习算法有支持向量机。</p>
<p><strong>强化学习</strong>：在这种学习模式下，输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻作出调整。常见的强化学习算法有时间差学习。</p>
<hr>
<p>​    按照<strong>算法类似性</strong>分为决策树学习、回归、聚类、人工神经网络</p>
<p><strong>决策树</strong>：根据数据的属性采用树状结构建立决策模型。决策树模型常常用来解决分类和回归问题。常见的算法包括 CART (Classification And Regression Tree)、ID3、C4.5、随机森林 (Random Forest) 等。</p>
<p><strong>回归算法</strong>：试图采用对误差的衡量来探索变量之间的关系的一类算法。常见的回归算法包括最小二乘法 (Least Square)、逻辑回归 (Logistic Regression)、逐步式回归 (Stepwise Regression) 等。</p>
<p><strong>聚类算法</strong>：通常按照中心点或者分层的方式对输入数据进行归并。所有的聚类算法都试图找到数据的内在结构，以便按照最大的共同点将数据进行归类。常见的聚类算法包括 K-Means 算法以及期望最大化算法 (Expectation Maximization) 等。</p>
<p><strong>人工神经网络</strong>：模拟生物神经网络，是一类模式匹配算法。通常用于解决分类和回归问题。人工神经网络算法包括感知器神经网络 (Perceptron Neural Network) 、反向传递 (Back Propagation) 和<a href="http://lib.csdn.net/base/deeplearning" target="_blank" rel="external">深度学习</a>等。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>《统计学习方法》<br>《The Elements of Statistical Learning 》<br>《Machine Learning A Probabilistic Perspective》<br><a href="http://note.youdao.com/noteshare?id=a2e5bda9a0319920080a19a192177b96&amp;sub=wcp1438842603044242" target="_blank" rel="external">Top 10 algorithms in data mining</a></p>

      
      
        <div class="page-reward">
          <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang" title="打赏，支持一下">赏</a></p>
          <div class="hide_box"></div>
          <div class="shang_box">
            <a class="shang_close" href="javascript:void(0)" onclick="dashangToggle()" title="关闭">×</a>
            <div class="shang_tit">
              <p>纯属好玩</p>
            </div>
            <div class="shang_payimg">
              <img src="/img/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
            </div>
              <div class="pay_explain">扫码打赏，你说多少就多少</div>
            <div class="shang_payselect">
              
                <div class="pay_item checked" data-id="alipay">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/alipayimg.jpg" alt="支付宝" /></span>
                </div>
              
              
                <div class="pay_item" data-id="wechat">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/wechatimg.jpg" alt="微信" /></span>
                </div>
              
            </div>
            <div class="shang_info">
              <p>打开<span id="shang_pay_txt">支付宝</span>扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
        </div>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js"></script>
        <script type="text/javascript">
          $(".pay_item").click(function(){
            $(this).addClass('checked').siblings('.pay_item').removeClass('checked');
            var dataid=$(this).attr('data-id');
            $(".shang_payimg img").attr("src","/img/"+dataid+"img.jpg");
            $("#shang_pay_txt").text(dataid=="alipay"?"支付宝":"微信");
          });
          function dashangToggle(){
            $(".hide_box").fadeToggle();
            $(".shang_box").fadeToggle();
          }
        </script>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/">『数据挖掘十大算法 』笔记二：SVM-支持向量机</a></p>
        <p><span>文章作者:</span><a href="/" title="访问 AaronChou 的个人博客">AaronChou</a></p>
        <p><span>发布时间:</span>2016年01月31日 - 15时30分</p>
        <p><span>最后更新:</span>2017年03月21日 - 10时16分</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/" title="『数据挖掘十大算法 』笔记二：SVM-支持向量机">https://insanelife.github.io/2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/</a>
            <span class="copy-path" data-clipboard-text="原文: https://insanelife.github.io/2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/　　作者: AaronChou" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script src="/js/clipboard.min.js"></script>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)" target = "_blank">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



<nav id="article-nav">
  
    <a href="/2016/03/02/不平衡学习的方法 Learning from Imbalanced Data/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          不平衡学习的方法 Learning from Imbalanced Data
        
      </div>
    </a>
  
  
    <a href="/2016/01/15/『数据挖掘十大算法 』笔记一：决策树/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">『数据挖掘十大算法 』笔记一：决策树</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>

    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#数据挖掘Top-10算法"><span class="toc-number">1.</span> <span class="toc-text">数据挖掘Top 10算法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#支持向量机"><span class="toc-number">2.</span> <span class="toc-text">支持向量机</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#线性可分支持向量机"><span class="toc-number">3.</span> <span class="toc-text">线性可分支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#函数间隔和几何间隔"><span class="toc-number">3.1.</span> <span class="toc-text">函数间隔和几何间隔</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#间隔最大化"><span class="toc-number">3.2.</span> <span class="toc-text">间隔最大化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#间隔最大化算法"><span class="toc-number">3.2.1.</span> <span class="toc-text">间隔最大化算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#支持向量和间隔边界"><span class="toc-number">3.2.2.</span> <span class="toc-text">支持向量和间隔边界</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#学习的对偶算法"><span class="toc-number">3.3.</span> <span class="toc-text">学习的对偶算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#线性可分支持向量机学习算法"><span class="toc-number">3.3.1.</span> <span class="toc-text">线性可分支持向量机学习算法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#线性支持向量机和软间隔最大化"><span class="toc-number">4.</span> <span class="toc-text">线性支持向量机和软间隔最大化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#线性支持向量机学习算法"><span class="toc-number">4.1.</span> <span class="toc-text">线性支持向量机学习算法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#非线性支持向量机和核函数"><span class="toc-number">5.</span> <span class="toc-text">非线性支持向量机和核函数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#核技巧"><span class="toc-number">5.1.</span> <span class="toc-text">核技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#非线性分类问题"><span class="toc-number">5.1.1.</span> <span class="toc-text">非线性分类问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#核函数定义"><span class="toc-number">5.1.2.</span> <span class="toc-text">核函数定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#核技巧在支持向量机中的应用"><span class="toc-number">5.1.3.</span> <span class="toc-text">核技巧在支持向量机中的应用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正定核"><span class="toc-number">5.2.</span> <span class="toc-text">正定核</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#常用核函数"><span class="toc-number">5.3.</span> <span class="toc-text">常用核函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#非线性支持向量机学习算法"><span class="toc-number">5.4.</span> <span class="toc-text">非线性支持向量机学习算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#"><span class="toc-number">5.5.</span> <span class="toc-text"> </span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#附录"><span class="toc-number">6.</span> <span class="toc-text">附录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#算法分类"><span class="toc-number">6.1.</span> <span class="toc-text">算法分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-number">6.2.</span> <span class="toc-text">参考资料</span></a></li></ol></li></ol>
</div>
<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script>
    var valueHide = "隐藏目录";
    var valueShow = "显示目录";

    if ($(".left-col").is(":hidden")) {
        $("#tocButton").attr("value", valueShow);
    }
    $("#tocButton").click(function() {
        if ($("#toc").is(":hidden")) {
            $("#tocButton").attr("value", valueHide);
            $("#toc").slideDown(320);
        }
        else {
            $("#tocButton").attr("value", valueShow);
            $("#toc").slideUp(350);
        }
    })
    if ($(".toc").length < 1) {
        $("#toc, #tocButton").hide();
    }
</script>





<div class="bdsharebuttonbox">
	<a href="#" class="fx fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="fx fa-weixin bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="fx fa-qq bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
	<a href="#" class="fx fa-facebook-official bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
	<a href="#" class="fx fa-twitter bds_twi" data-cmd="twi" title="分享到Twitter"></a>
	<a href="#" class="fx fa-linkedin bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
	<a href="#" class="fx fa-files-o bds_copy" data-cmd="copy" title="分享到复制网址"></a>
</div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>




    
      <div class="duoshuo" id="comments">
    <!-- 多说评论框 start -->
    <div class="ds-thread" data-thread-key="2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/" data-title="『数据挖掘十大算法 』笔记二：SVM-支持向量机" data-url="https://insanelife.github.io/2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/"></div>
    <!-- 多说评论框 end -->
    <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
    <script type="text/javascript">
    var duoshuoQuery = {short_name:"null"};
    (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = '/js/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] 
         || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
    </script>
    <!-- 多说公共JS代码 end -->
</div>

    



    <div class="scroll" id="post-nav-button">
        
            <a href="/2016/03/02/不平衡学习的方法 Learning from Imbalanced Data/" title="上一篇: 不平衡学习的方法 Learning from Imbalanced Data">
                <i class="fa fa-angle-left"></i>
            </a>
        
        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>
        
            <a href="/2016/01/15/『数据挖掘十大算法 』笔记一：决策树/" title="下一篇: 『数据挖掘十大算法 』笔记一：决策树">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>
    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/31/『 天池竞赛』O2O优惠券使用预测思路总结/">『 天池竞赛』O2O优惠券使用预测思路总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/02/不平衡学习的方法 Learning from Imbalanced Data/">不平衡学习的方法 Learning from Imbalanced Data</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/01/31/『数据挖掘十大算法 』笔记二：SVM-支持向量机/">『数据挖掘十大算法 』笔记二：SVM-支持向量机</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/01/15/『数据挖掘十大算法 』笔记一：决策树/">『数据挖掘十大算法 』笔记一：决策树</a></li></ul>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
    <script>
        $(".post-list").addClass("toc-article");
        $(".post-list-item a").attr("target","_blank");
        $("#post-nav-button > a:nth-child(2)").click(function() {
            $(".fa-bars, .fa-times").toggle();
            $(".post-list").toggle(300);
            if ($(".toc").length > 0) {
                $("#toc, #tocButton").toggle(200, function() {
                    if ($(".switch-area").is(":visible")) {
                        $("#tocButton").attr("value", valueHide);
                        }
                    })
            }
            else {
            }
        })
    </script>



    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2017 AaronChou
            </div>
            <div class="footer-right">
               <!--#//<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/luuman/hexo-theme-spfk" target="_blank">spfk</a> by luuman
				-->
			</div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>

    <script>
        $(document).ready(function() {
            var backgroundnum = 24;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(

            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>